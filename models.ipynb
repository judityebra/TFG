{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "335b71b0",
   "metadata": {},
   "source": [
    "#### VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d5261b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1e78636",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_carpeta = os.path.join(os.getcwd(), 'csvs')\n",
    "\n",
    "average_clustering_fa = pd.read_csv(os.path.join(ruta_carpeta, 'average_clustering_FA.csv'))\n",
    "average_clustering_gm = pd.read_csv(os.path.join(ruta_carpeta, 'average_clustering_GM.csv'))\n",
    "average_clustering_rs = pd.read_csv(os.path.join(ruta_carpeta, 'average_clustering_RS.csv'))\n",
    "\n",
    "average_degree_fa = pd.read_csv(os.path.join(ruta_carpeta, 'average_degree_FA.csv'))\n",
    "average_degree_gm = pd.read_csv(os.path.join(ruta_carpeta, 'average_degree_GM.csv'))\n",
    "average_degree_rs = pd.read_csv(os.path.join(ruta_carpeta, 'average_degree_RS.csv'))\n",
    "\n",
    "betweenness_fa = pd.read_csv(os.path.join(ruta_carpeta, 'betweenness_fa.csv'))\n",
    "betweenness_gm = pd.read_csv(os.path.join(ruta_carpeta, 'betweenness_gm.csv'))\n",
    "betweenness_rs = pd.read_csv(os.path.join(ruta_carpeta, 'betweenness_rs.csv'))\n",
    "\n",
    "closeness_fa = pd.read_csv(os.path.join(ruta_carpeta, 'closeness_fa.csv'))\n",
    "closeness_gm = pd.read_csv(os.path.join(ruta_carpeta, 'closeness_gm.csv'))\n",
    "closeness_rs = pd.read_csv(os.path.join(ruta_carpeta, 'closeness_rs.csv'))\n",
    "\n",
    "density_fa = pd.read_csv(os.path.join(ruta_carpeta, 'density_FA.csv'))\n",
    "density_gm = pd.read_csv(os.path.join(ruta_carpeta, 'density_GM.csv'))\n",
    "density_rs = pd.read_csv(os.path.join(ruta_carpeta, 'density_RS.csv'))\n",
    "\n",
    "degree_fa = pd.read_csv(os.path.join(ruta_carpeta, 'degree_fa.csv'))\n",
    "degree_gm = pd.read_csv(os.path.join(ruta_carpeta, 'degree_gm.csv'))\n",
    "degree_rs = pd.read_csv(os.path.join(ruta_carpeta, 'degree_rs.csv'))\n",
    "\n",
    "eigenvector_fa = pd.read_csv(os.path.join(ruta_carpeta, 'eigenvector_fa.csv'))\n",
    "eigenvector_gm = pd.read_csv(os.path.join(ruta_carpeta, 'eigenvector_gm.csv'))\n",
    "eigenvector_rs = pd.read_csv(os.path.join(ruta_carpeta, 'eigenvector_rs.csv'))\n",
    "\n",
    "strength_fa = pd.read_csv(os.path.join(ruta_carpeta, 'strength_fa.csv'))\n",
    "strength_gm = pd.read_csv(os.path.join(ruta_carpeta, 'strength_gm.csv'))\n",
    "strength_rs = pd.read_csv(os.path.join(ruta_carpeta, 'strength_rs.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "134490f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath = \"dades_tfg/data\"\n",
    "demographics = pd.read_csv(os.path.join(basepath, \"demographics.csv\"))\n",
    "demographics_N = pd.read_csv(os.path.join(basepath, \"demographics_N.csv\"))\n",
    "nodes = pd.read_csv(os.path.join(basepath, \"nodes.csv\"))\n",
    "basepath_FA = os.path.join(basepath, \"FA\")\n",
    "basepath_GM = os.path.join(basepath, \"GM\")\n",
    "basepath_RS = os.path.join(basepath, \"RS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fd917a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [\"{:04d}.csv\".format(x) for x in demographics[\"id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b900271b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_FA = np.zeros(shape=(len(filenames), 76, 76))\n",
    "data_GM = np.zeros(shape=(len(filenames), 76, 76))\n",
    "data_RS = np.zeros(shape=(len(filenames), 76, 76))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a763e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, filename in enumerate(filenames):\n",
    "    df_FA = pd.read_csv(os.path.join(basepath_FA, filename), header=None)\n",
    "    data_FA[i,:,:] = df_FA.values\n",
    "    \n",
    "    df_GM = pd.read_csv(os.path.join(basepath_GM, filename), header=None)\n",
    "    data_GM[i,:,:] = df_GM.values\n",
    "    \n",
    "    df_RS = pd.read_csv(os.path.join(basepath_RS, filename), header=None)\n",
    "    data_RS[i,:,:] = df_RS.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcf845d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath_FA_N = \"dades_tfg/data/Naples/DTI_networks\"\n",
    "basepath_GM_N = \"dades_tfg/data/Naples/GM_networks\"\n",
    "basepath_RS_N = \"dades_tfg/data/Naples/rsfmri_networks\"\n",
    "\n",
    "# Listar nombres de archivos CSV en cada carpeta\n",
    "filenames_FA_N = sorted([f for f in os.listdir(basepath_FA_N) if f.endswith('.csv')])\n",
    "filenames_GM_N = sorted([f for f in os.listdir(basepath_GM_N) if f.endswith('.csv')])\n",
    "filenames_RS_N = sorted([f for f in os.listdir(basepath_RS_N) if f.endswith('.csv')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a03bf4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar arrays para almacenar los datos\n",
    "data_FA_N = np.zeros((len(filenames_FA_N), 76, 76))  \n",
    "data_GM_N = np.zeros((len(filenames_GM_N), 76, 76))\n",
    "data_RS_N = np.zeros((len(filenames_RS_N), 76, 76))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "333ba88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FA\n",
    "for i, filename in enumerate(filenames_FA_N):\n",
    "    df_FA_N = pd.read_csv(os.path.join(basepath_FA_N, filename), header=None)\n",
    "    data_FA_N[i, :, :] = df_FA_N.values\n",
    "\n",
    "#  GM\n",
    "for i, filename in enumerate(filenames_GM_N):\n",
    "    df_GM_N = pd.read_csv(os.path.join(basepath_GM_N, filename), header=None)\n",
    "    data_GM_N[i, :, :] = df_GM_N.values\n",
    "\n",
    "#  RS\n",
    "for i, filename in enumerate(filenames_RS_N):\n",
    "    df_RS_N = pd.read_csv(os.path.join(basepath_RS_N, filename), header=None)\n",
    "    data_RS_N[i, :, :] = df_RS_N.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2d46b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples_FA = len(data_FA)\n",
    "num_samples_FA_N = len(data_FA_N)\n",
    "num_samples_GM = len(data_FA)\n",
    "num_samples_GM_N = len(data_FA_N)\n",
    "num_samples_RS = len(data_FA)\n",
    "num_samples_RS_N = len(data_FA_N)\n",
    "\n",
    "\n",
    "data_FA_combined = np.zeros((num_samples_FA + num_samples_FA_N, 76, 76))  \n",
    "data_FA_combined[:num_samples_FA, :, :] = data_FA\n",
    "data_FA_combined[num_samples_FA:, :, :] = data_FA_N\n",
    "\n",
    "\n",
    "data_GM_combined = np.zeros((num_samples_GM + num_samples_GM_N, 76, 76))  \n",
    "data_GM_combined[:num_samples_GM, :, :] = data_GM\n",
    "data_GM_combined[num_samples_GM:, :, :] = data_GM_N\n",
    "\n",
    "\n",
    "data_RS_combined = np.zeros((num_samples_RS + num_samples_RS_N, 76, 76))  \n",
    "data_RS_combined[:num_samples_RS, :, :] = data_RS\n",
    "data_RS_combined[num_samples_RS:, :, :] = data_RS_N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0887a49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics_N['mstype'] = demographics_N['mstype'].apply(lambda x: 0 if x == -1 else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f111793b",
   "metadata": {
    "id": "f111793b"
   },
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4770b945",
   "metadata": {
    "id": "4770b945"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf59f29",
   "metadata": {
    "id": "ccf59f29"
   },
   "source": [
    "### GENERAL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca5046d",
   "metadata": {
    "id": "aca5046d"
   },
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fcdca00",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2fcdca00",
    "outputId": "d55c88ca-812d-4ea9-ed15-5e01578fdca6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8518518518518519\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85        41\n",
      "           1       0.85      0.85      0.85        40\n",
      "\n",
      "    accuracy                           0.85        81\n",
      "   macro avg       0.85      0.85      0.85        81\n",
      "weighted avg       0.85      0.85      0.85        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# data_FA;-> caracterÃ­stiques, mstype -> prova\n",
    "X = data_FA_combined.reshape(data_FA_combined.shape[0], -1)  # matrius-> vectors\n",
    "y = demographics_N['mstype'].values\n",
    "\n",
    "# split train test\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "svm = SVC(kernel='linear', C=1)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "564f0521",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "564f0521",
    "outputId": "d914c8ed-7df8-4f03-9805-32d668697e57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8641975308641975\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.83      0.86        41\n",
      "           1       0.84      0.90      0.87        40\n",
      "\n",
      "    accuracy                           0.86        81\n",
      "   macro avg       0.87      0.86      0.86        81\n",
      "weighted avg       0.87      0.86      0.86        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# data_GM;-> caracterÃ­stiques, mstype -> prova\n",
    "X = data_GM_combined.reshape(data_GM_combined.shape[0], -1)  # matrius-> vectors\n",
    "y = demographics_N['mstype'].values\n",
    "\n",
    "# split train test\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "svm = SVC(kernel='linear', C=1)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ae811b4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3ae811b4",
    "outputId": "074d4eba-9679-4e53-9c5d-a6a02f30deb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9259259259259259\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.88      0.92        41\n",
      "           1       0.89      0.97      0.93        40\n",
      "\n",
      "    accuracy                           0.93        81\n",
      "   macro avg       0.93      0.93      0.93        81\n",
      "weighted avg       0.93      0.93      0.93        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# data_RS-> caracterÃ­stiques, mstype -> prova\n",
    "X = data_RS_combined.reshape(data_RS_combined.shape[0], -1)  # matrius-> vectors\n",
    "y = demographics_N['mstype'].values\n",
    "\n",
    "# split train test\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "svm = SVC(kernel='linear', C=1)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71fcb5f",
   "metadata": {
    "id": "a71fcb5f"
   },
   "source": [
    "#### LOGISTIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5290a61a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5290a61a",
    "outputId": "69484208-c95f-4914-c5bf-533d9b9d983d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8641975308641975\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.80      0.86        41\n",
      "           1       0.82      0.93      0.87        40\n",
      "\n",
      "    accuracy                           0.86        81\n",
      "   macro avg       0.87      0.86      0.86        81\n",
      "weighted avg       0.87      0.86      0.86        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = data_FA_combined.reshape(data_FA_combined.shape[0], -1)\n",
    "y = demographics_N['mstype'].values\n",
    "y = (y > 0).astype(int)\n",
    "\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=10000)\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b33255a2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b33255a2",
    "outputId": "df6c3918-d264-47d5-aecf-0a1af1374b04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9135802469135802\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.88      0.91        41\n",
      "           1       0.88      0.95      0.92        40\n",
      "\n",
      "    accuracy                           0.91        81\n",
      "   macro avg       0.92      0.91      0.91        81\n",
      "weighted avg       0.92      0.91      0.91        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = data_GM_combined.reshape(data_GM_combined.shape[0], -1)\n",
    "y = demographics_N['mstype'].values\n",
    "y = (y > 0).astype(int)\n",
    "\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=10000)\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1550faa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e1550faa",
    "outputId": "84915c46-3124-400f-c330-6345cdf89d99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9382716049382716\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.94        41\n",
      "           1       0.89      1.00      0.94        40\n",
      "\n",
      "    accuracy                           0.94        81\n",
      "   macro avg       0.94      0.94      0.94        81\n",
      "weighted avg       0.95      0.94      0.94        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = data_RS_combined.reshape(data_RS_combined.shape[0], -1)\n",
    "y = demographics_N['mstype'].values\n",
    "y = (y > 0).astype(int)\n",
    "\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred)) #GRAN BIAIX\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bad48c92",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bad48c92",
    "outputId": "c305cb8d-81f4-4fc2-c7f6-7e934738d968"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: {0: 82, 1: 107}\n",
      "test: {0: 41, 1: 40}\n"
     ]
    }
   ],
   "source": [
    "#VEIEM EL BIAIX\n",
    "unique_train, counts_train = np.unique(y_train, return_counts=True)\n",
    "unique_test, counts_test = np.unique(y_test, return_counts=True)\n",
    "\n",
    "print(f\"train: {dict(zip(unique_train, counts_train))}\")\n",
    "print(f\"test: {dict(zip(unique_test, counts_test))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22e0dc2",
   "metadata": {
    "id": "c22e0dc2"
   },
   "source": [
    "### NODES\n",
    "- degree\n",
    "- strength\n",
    "- closeness centrality\n",
    "- betwennes centrality\n",
    "- eigenvector centrality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097d0cb0",
   "metadata": {
    "id": "097d0cb0"
   },
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8315906f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8315906f",
    "outputId": "55333c54-e081-4825-a8e3-f49b8d102cfc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset (X, y): (189, 76) - (189,)\n",
      "Size of test dataset  (X, y): (81, 76) - (81,)\n",
      "Accuracy: 0.8765432098765432\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.85      0.88        41\n",
      "           1       0.86      0.90      0.88        40\n",
      "\n",
      "    accuracy                           0.88        81\n",
      "   macro avg       0.88      0.88      0.88        81\n",
      "weighted avg       0.88      0.88      0.88        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = degree_fa\n",
    "y = demographics_N['mstype'].values\n",
    "\n",
    "# split train test\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "print(\"Size of train dataset (X, y): {} - {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Size of test dataset  (X, y): {} - {}\".format(X_test.shape, y_test.shape))\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "svm = SVC(kernel='linear', C=1)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fab0fdeb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fab0fdeb",
    "outputId": "ec5e8c8c-76f6-420a-acb3-ee021cc2969b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset (X, y): (189, 76) - (189,)\n",
      "Size of test dataset  (X, y): (81, 76) - (81,)\n",
      "Accuracy: 0.8395061728395061\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.76      0.83        41\n",
      "           1       0.79      0.93      0.85        40\n",
      "\n",
      "    accuracy                           0.84        81\n",
      "   macro avg       0.85      0.84      0.84        81\n",
      "weighted avg       0.85      0.84      0.84        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = strength_fa\n",
    "y = demographics_N['mstype'].values\n",
    "\n",
    "# split train test\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "print(\"Size of train dataset (X, y): {} - {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Size of test dataset  (X, y): {} - {}\".format(X_test.shape, y_test.shape))\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "svm = SVC(kernel='linear', C=1)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f23f437",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6f23f437",
    "outputId": "c7f1a088-aed3-4cc4-a3d5-b549d131bc1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset (X, y): (189, 76) - (189,)\n",
      "Size of test dataset  (X, y): (81, 76) - (81,)\n",
      "Accuracy: 0.8024691358024691\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.78      0.80        41\n",
      "           1       0.79      0.82      0.80        40\n",
      "\n",
      "    accuracy                           0.80        81\n",
      "   macro avg       0.80      0.80      0.80        81\n",
      "weighted avg       0.80      0.80      0.80        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = closeness_fa\n",
    "y = demographics_N['mstype'].values\n",
    "\n",
    "# split train test\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "print(\"Size of train dataset (X, y): {} - {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Size of test dataset  (X, y): {} - {}\".format(X_test.shape, y_test.shape))\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "svm = SVC(kernel='linear', C=1)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dfcdb4a1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dfcdb4a1",
    "outputId": "f5b2e025-61e9-4f5a-b4a3-5fd3830f682a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset (X, y): (189, 76) - (189,)\n",
      "Size of test dataset  (X, y): (81, 76) - (81,)\n",
      "Accuracy: 0.8641975308641975\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.85      0.86        41\n",
      "           1       0.85      0.88      0.86        40\n",
      "\n",
      "    accuracy                           0.86        81\n",
      "   macro avg       0.86      0.86      0.86        81\n",
      "weighted avg       0.86      0.86      0.86        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = betweenness_fa\n",
    "y = demographics_N['mstype'].values\n",
    "\n",
    "# split train test\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "print(\"Size of train dataset (X, y): {} - {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Size of test dataset  (X, y): {} - {}\".format(X_test.shape, y_test.shape))\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "svm = SVC(kernel='linear', C=1)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f2cfcea",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8f2cfcea",
    "outputId": "b1f174d7-441f-4ed3-9e93-81a45988bbd9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset (X, y): (189, 76) - (189,)\n",
      "Size of test dataset  (X, y): (81, 76) - (81,)\n",
      "Accuracy: 0.8395061728395061\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.78      0.83        41\n",
      "           1       0.80      0.90      0.85        40\n",
      "\n",
      "    accuracy                           0.84        81\n",
      "   macro avg       0.84      0.84      0.84        81\n",
      "weighted avg       0.84      0.84      0.84        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = eigenvector_fa\n",
    "y = demographics_N['mstype'].values\n",
    "\n",
    "# split train test\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "print(\"Size of train dataset (X, y): {} - {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Size of test dataset  (X, y): {} - {}\".format(X_test.shape, y_test.shape))\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "svm = SVC(kernel='linear', C=1)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0906c70d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0906c70d",
    "outputId": "1afe3618-4dcc-4b8b-b736-843b3997c693"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset (X, y): (189, 76) - (189,)\n",
      "Size of test dataset  (X, y): (81, 76) - (81,)\n",
      "Accuracy: 0.9259259259259259\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.90      0.93        41\n",
      "           1       0.90      0.95      0.93        40\n",
      "\n",
      "    accuracy                           0.93        81\n",
      "   macro avg       0.93      0.93      0.93        81\n",
      "weighted avg       0.93      0.93      0.93        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = degree_gm\n",
    "y = demographics_N['mstype'].values\n",
    "\n",
    "# split train test\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "print(\"Size of train dataset (X, y): {} - {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Size of test dataset  (X, y): {} - {}\".format(X_test.shape, y_test.shape))\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "svm = SVC(kernel='linear', C=1)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a647516",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9a647516",
    "outputId": "1eabfd31-514e-4f7c-891a-728b0ee57e9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset (X, y): (189, 76) - (189,)\n",
      "Size of test dataset  (X, y): (81, 76) - (81,)\n",
      "Accuracy: 0.9012345679012346\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.85      0.90        41\n",
      "           1       0.86      0.95      0.90        40\n",
      "\n",
      "    accuracy                           0.90        81\n",
      "   macro avg       0.90      0.90      0.90        81\n",
      "weighted avg       0.91      0.90      0.90        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = strength_gm\n",
    "y = demographics_N['mstype'].values\n",
    "\n",
    "# split train test\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "print(\"Size of train dataset (X, y): {} - {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Size of test dataset  (X, y): {} - {}\".format(X_test.shape, y_test.shape))\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "svm = SVC(kernel='linear', C=1)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "39caa6ea",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "39caa6ea",
    "outputId": "816b4bb2-1ad8-4492-ca0a-dc671dfd9099"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset (X, y): (189, 76) - (189,)\n",
      "Size of test dataset  (X, y): (81, 76) - (81,)\n",
      "Accuracy: 0.8518518518518519\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86        41\n",
      "           1       0.89      0.80      0.84        40\n",
      "\n",
      "    accuracy                           0.85        81\n",
      "   macro avg       0.86      0.85      0.85        81\n",
      "weighted avg       0.86      0.85      0.85        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = closeness_gm\n",
    "y = demographics_N['mstype'].values\n",
    "\n",
    "# split train test\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "print(\"Size of train dataset (X, y): {} - {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Size of test dataset  (X, y): {} - {}\".format(X_test.shape, y_test.shape))\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "svm = SVC(kernel='linear', C=1)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "60f70b0b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "60f70b0b",
    "outputId": "104c30e5-4f77-4ad3-bba8-7147bb9b67f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset (X, y): (189, 76) - (189,)\n",
      "Size of test dataset  (X, y): (81, 76) - (81,)\n",
      "Accuracy: 0.8765432098765432\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.83      0.87        41\n",
      "           1       0.84      0.93      0.88        40\n",
      "\n",
      "    accuracy                           0.88        81\n",
      "   macro avg       0.88      0.88      0.88        81\n",
      "weighted avg       0.88      0.88      0.88        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = betweenness_gm\n",
    "y = demographics_N['mstype'].values\n",
    "\n",
    "# split train test\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "print(\"Size of train dataset (X, y): {} - {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Size of test dataset  (X, y): {} - {}\".format(X_test.shape, y_test.shape))\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "svm = SVC(kernel='linear', C=1, class_weight='balanced')\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4392e7bc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4392e7bc",
    "outputId": "61727ab9-e3a6-4c95-be79-8ba8857f2fa5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset (X, y): (189, 76) - (189,)\n",
      "Size of test dataset  (X, y): (81, 76) - (81,)\n",
      "Accuracy: 0.9259259259259259\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.88      0.92        41\n",
      "           1       0.89      0.97      0.93        40\n",
      "\n",
      "    accuracy                           0.93        81\n",
      "   macro avg       0.93      0.93      0.93        81\n",
      "weighted avg       0.93      0.93      0.93        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = eigenvector_gm\n",
    "y = demographics_N['mstype'].values\n",
    "\n",
    "# split train test\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "print(\"Size of train dataset (X, y): {} - {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Size of test dataset  (X, y): {} - {}\".format(X_test.shape, y_test.shape))\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "svm = SVC(kernel='linear', C=1, class_weight='balanced')\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "75a7811d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "75a7811d",
    "outputId": "ee190c59-8d57-4698-9db6-b2c41b0208e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset (X, y): (189, 76) - (189,)\n",
      "Size of test dataset  (X, y): (81, 76) - (81,)\n",
      "Accuracy: 0.7407407407407407\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.83      0.76        41\n",
      "           1       0.79      0.65      0.71        40\n",
      "\n",
      "    accuracy                           0.74        81\n",
      "   macro avg       0.75      0.74      0.74        81\n",
      "weighted avg       0.75      0.74      0.74        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = degree_rs\n",
    "y = demographics_N['mstype'].values\n",
    "\n",
    "# split train test\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "print(\"Size of train dataset (X, y): {} - {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Size of test dataset  (X, y): {} - {}\".format(X_test.shape, y_test.shape))\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "svm = SVC(kernel='linear', C=1)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "58571739",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "58571739",
    "outputId": "5ee92671-6487-4de1-9310-70cfee7f3acd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset (X, y): (189, 76) - (189,)\n",
      "Size of test dataset  (X, y): (81, 76) - (81,)\n",
      "Accuracy: 0.6666666666666666\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.80      0.71        41\n",
      "           1       0.72      0.53      0.61        40\n",
      "\n",
      "    accuracy                           0.67        81\n",
      "   macro avg       0.68      0.66      0.66        81\n",
      "weighted avg       0.68      0.67      0.66        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = strength_rs\n",
    "y = demographics_N['mstype'].values\n",
    "\n",
    "# split train test\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "print(\"Size of train dataset (X, y): {} - {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Size of test dataset  (X, y): {} - {}\".format(X_test.shape, y_test.shape))\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "svm = SVC(kernel='linear', C=1)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9efa81fe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9efa81fe",
    "outputId": "380fa0a2-30be-4847-931d-ce614f3d9c31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset (X, y): (189, 76) - (189,)\n",
      "Size of test dataset  (X, y): (81, 76) - (81,)\n",
      "Accuracy: 0.8765432098765432\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.93      0.88        41\n",
      "           1       0.92      0.82      0.87        40\n",
      "\n",
      "    accuracy                           0.88        81\n",
      "   macro avg       0.88      0.88      0.88        81\n",
      "weighted avg       0.88      0.88      0.88        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = closeness_rs\n",
    "y = demographics_N['mstype'].values\n",
    "\n",
    "# split train test\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "print(\"Size of train dataset (X, y): {} - {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Size of test dataset  (X, y): {} - {}\".format(X_test.shape, y_test.shape))\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "svm = SVC(kernel='linear', C=1)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cc171ebd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cc171ebd",
    "outputId": "005aed00-e782-4248-8a07-658f55ecbd80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset (X, y): (189, 76) - (189,)\n",
      "Size of test dataset  (X, y): (81, 76) - (81,)\n",
      "Accuracy: 0.6790123456790124\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.71      0.69        41\n",
      "           1       0.68      0.65      0.67        40\n",
      "\n",
      "    accuracy                           0.68        81\n",
      "   macro avg       0.68      0.68      0.68        81\n",
      "weighted avg       0.68      0.68      0.68        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = betweenness_rs\n",
    "y = demographics_N['mstype'].values\n",
    "\n",
    "# split train test\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "print(\"Size of train dataset (X, y): {} - {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Size of test dataset  (X, y): {} - {}\".format(X_test.shape, y_test.shape))\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "svm = SVC(kernel='linear', C=1)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "197fde68",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "197fde68",
    "outputId": "0df8bb95-298c-413c-95ff-8d3b07eea83a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset (X, y): (189, 76) - (189,)\n",
      "Size of test dataset  (X, y): (81, 76) - (81,)\n",
      "Accuracy: 0.6666666666666666\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.68      0.67        41\n",
      "           1       0.67      0.65      0.66        40\n",
      "\n",
      "    accuracy                           0.67        81\n",
      "   macro avg       0.67      0.67      0.67        81\n",
      "weighted avg       0.67      0.67      0.67        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = eigenvector_rs\n",
    "y = demographics_N['mstype'].values\n",
    "\n",
    "# split train test\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "print(\"Size of train dataset (X, y): {} - {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Size of test dataset  (X, y): {} - {}\".format(X_test.shape, y_test.shape))\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "svm = SVC(kernel='linear', C=1)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ae9dff",
   "metadata": {
    "id": "e9ae9dff"
   },
   "source": [
    "#### LOGISTIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "58e5013d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "58e5013d",
    "outputId": "03b12ac4-ebf4-4c27-940a-fb6142a750e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset (X, y): (189, 76) - (189,)\n",
      "Size of test dataset  (X, y): (81, 76) - (81,)\n",
      "Accuracy: 0.8395061728395061\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.85      0.84        41\n",
      "           1       0.85      0.82      0.84        40\n",
      "\n",
      "    accuracy                           0.84        81\n",
      "   macro avg       0.84      0.84      0.84        81\n",
      "weighted avg       0.84      0.84      0.84        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = degree_fa\n",
    "y = demographics_N['mstype'].values\n",
    "\n",
    "# split train test\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"Size of train dataset (X, y): {} - {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Size of test dataset  (X, y): {} - {}\".format(X_test.shape, y_test.shape))\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=500)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8cfa30e6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8cfa30e6",
    "outputId": "c3ca7dda-713b-4d7d-ada9-6b54a932719a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset (X, y): (189, 76) - (189,)\n",
      "Size of test dataset  (X, y): (81, 76) - (81,)\n",
      "Accuracy: 0.8271604938271605\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83        41\n",
      "           1       0.82      0.82      0.82        40\n",
      "\n",
      "    accuracy                           0.83        81\n",
      "   macro avg       0.83      0.83      0.83        81\n",
      "weighted avg       0.83      0.83      0.83        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = strength_fa\n",
    "y = demographics_N['mstype'].values\n",
    "\n",
    "# split train test\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"Size of train dataset (X, y): {} - {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Size of test dataset  (X, y): {} - {}\".format(X_test.shape, y_test.shape))\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=500)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "efc73173",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "efc73173",
    "outputId": "01c13779-8a81-4c9e-8472-875a81bf38ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset (X, y): (189, 76) - (189,)\n",
      "Size of test dataset  (X, y): (81, 76) - (81,)\n",
      "Accuracy: 0.8395061728395061\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84        41\n",
      "           1       0.83      0.85      0.84        40\n",
      "\n",
      "    accuracy                           0.84        81\n",
      "   macro avg       0.84      0.84      0.84        81\n",
      "weighted avg       0.84      0.84      0.84        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = closeness_fa\n",
    "y = demographics_N['mstype'].values\n",
    "\n",
    "# split train test\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"Size of train dataset (X, y): {} - {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Size of test dataset  (X, y): {} - {}\".format(X_test.shape, y_test.shape))\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=500, class_weight='balanced')\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8ab1170b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ab1170b",
    "outputId": "53fcbea5-a843-4503-9234-57c8dddf0c71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset (X, y): (189, 76) - (189,)\n",
      "Size of test dataset  (X, y): (81, 76) - (81,)\n",
      "Accuracy: 0.8888888888888888\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.88      0.89        41\n",
      "           1       0.88      0.90      0.89        40\n",
      "\n",
      "    accuracy                           0.89        81\n",
      "   macro avg       0.89      0.89      0.89        81\n",
      "weighted avg       0.89      0.89      0.89        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = betweenness_fa\n",
    "y = demographics_N['mstype'].values\n",
    "\n",
    "# split train test\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"Size of train dataset (X, y): {} - {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Size of test dataset  (X, y): {} - {}\".format(X_test.shape, y_test.shape))\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "01cd09d9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "01cd09d9",
    "outputId": "e1bbb35f-ced1-4486-b350-767a9c397b81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset (X, y): (189, 76) - (189,)\n",
      "Size of test dataset  (X, y): (81, 76) - (81,)\n",
      "Accuracy: 0.8518518518518519\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.80      0.85        41\n",
      "           1       0.82      0.90      0.86        40\n",
      "\n",
      "    accuracy                           0.85        81\n",
      "   macro avg       0.86      0.85      0.85        81\n",
      "weighted avg       0.86      0.85      0.85        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = eigenvector_fa\n",
    "y = demographics_N['mstype'].values\n",
    "\n",
    "# split train test\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"Size of train dataset (X, y): {} - {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Size of test dataset  (X, y): {} - {}\".format(X_test.shape, y_test.shape))\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=500)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6a87d772",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6a87d772",
    "outputId": "d712c208-c315-4d32-943d-f82c10880bbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset (X, y): (189, 76) - (189,)\n",
      "Size of test dataset  (X, y): (81, 76) - (81,)\n",
      "Accuracy: 0.9259259259259259\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.88      0.92        41\n",
      "           1       0.89      0.97      0.93        40\n",
      "\n",
      "    accuracy                           0.93        81\n",
      "   macro avg       0.93      0.93      0.93        81\n",
      "weighted avg       0.93      0.93      0.93        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = degree_gm\n",
    "y = demographics_N['mstype'].values\n",
    "\n",
    "# split train test\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"Size of train dataset (X, y): {} - {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Size of test dataset  (X, y): {} - {}\".format(X_test.shape, y_test.shape))\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=500, class_weight='balanced')\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "73f7d999",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "73f7d999",
    "outputId": "598e8227-2740-4501-e795-7165f15f1dc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset (X, y): (189, 76) - (189,)\n",
      "Size of test dataset  (X, y): (81, 76) - (81,)\n",
      "Accuracy: 0.9135802469135802\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.91        41\n",
      "           1       0.87      0.97      0.92        40\n",
      "\n",
      "    accuracy                           0.91        81\n",
      "   macro avg       0.92      0.91      0.91        81\n",
      "weighted avg       0.92      0.91      0.91        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = strength_gm\n",
    "y = demographics_N['mstype'].values\n",
    "\n",
    "# split train test\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"Size of train dataset (X, y): {} - {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Size of test dataset  (X, y): {} - {}\".format(X_test.shape, y_test.shape))\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=500, class_weight='balanced')\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "95ec3ecd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "95ec3ecd",
    "outputId": "c0f7ac01-42fc-4a35-ef45-6b46fcc00f89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset (X, y): (189, 76) - (189,)\n",
      "Size of test dataset  (X, y): (81, 76) - (81,)\n",
      "Accuracy: 0.9012345679012346\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.88      0.90        41\n",
      "           1       0.88      0.93      0.90        40\n",
      "\n",
      "    accuracy                           0.90        81\n",
      "   macro avg       0.90      0.90      0.90        81\n",
      "weighted avg       0.90      0.90      0.90        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = closeness_gm\n",
    "y = demographics_N['mstype'].values\n",
    "\n",
    "# split train test\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"Size of train dataset (X, y): {} - {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Size of test dataset  (X, y): {} - {}\".format(X_test.shape, y_test.shape))\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=500)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4083f9a6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4083f9a6",
    "outputId": "3297930c-f8ff-4289-ffac-a0da7a0e12d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset (X, y): (189, 76) - (189,)\n",
      "Size of test dataset  (X, y): (81, 76) - (81,)\n",
      "Accuracy: 0.9135802469135802\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.91        41\n",
      "           1       0.87      0.97      0.92        40\n",
      "\n",
      "    accuracy                           0.91        81\n",
      "   macro avg       0.92      0.91      0.91        81\n",
      "weighted avg       0.92      0.91      0.91        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = betweenness_gm\n",
    "y = demographics_N['mstype'].values\n",
    "\n",
    "# split train test\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"Size of train dataset (X, y): {} - {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Size of test dataset  (X, y): {} - {}\".format(X_test.shape, y_test.shape))\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "93b44f14",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "93b44f14",
    "outputId": "681fe9a3-35e6-4c15-eff1-7e38632a7b1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset (X, y): (189, 76) - (189,)\n",
      "Size of test dataset  (X, y): (81, 76) - (81,)\n",
      "Accuracy: 0.9382716049382716\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.94        41\n",
      "           1       0.89      1.00      0.94        40\n",
      "\n",
      "    accuracy                           0.94        81\n",
      "   macro avg       0.94      0.94      0.94        81\n",
      "weighted avg       0.95      0.94      0.94        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = eigenvector_gm\n",
    "y = demographics_N['mstype'].values\n",
    "\n",
    "# split train test\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"Size of train dataset (X, y): {} - {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Size of test dataset  (X, y): {} - {}\".format(X_test.shape, y_test.shape))\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=500, class_weight='balanced')\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0b5614ed",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0b5614ed",
    "outputId": "c86fb77c-6d66-4750-fb7e-b71914fdbaf7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset (X, y): (189, 76) - (189,)\n",
      "Size of test dataset  (X, y): (81, 76) - (81,)\n",
      "Accuracy: 0.7777777777777778\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.85      0.80        41\n",
      "           1       0.82      0.70      0.76        40\n",
      "\n",
      "    accuracy                           0.78        81\n",
      "   macro avg       0.78      0.78      0.78        81\n",
      "weighted avg       0.78      0.78      0.78        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = degree_rs\n",
    "y = demographics_N['mstype'].values\n",
    "\n",
    "# split train test\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"Size of train dataset (X, y): {} - {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Size of test dataset  (X, y): {} - {}\".format(X_test.shape, y_test.shape))\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "log_reg = LogisticRegression(class_weight='balanced')\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1ac3914f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1ac3914f",
    "outputId": "34e9b5ed-3913-4a0f-b229-e85520831904"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset (X, y): (189, 76) - (189,)\n",
      "Size of test dataset  (X, y): (81, 76) - (81,)\n",
      "Accuracy: 0.691358024691358\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.80      0.73        41\n",
      "           1       0.74      0.57      0.65        40\n",
      "\n",
      "    accuracy                           0.69        81\n",
      "   macro avg       0.70      0.69      0.69        81\n",
      "weighted avg       0.70      0.69      0.69        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = strength_rs\n",
    "y = demographics_N['mstype'].values\n",
    "\n",
    "# split train test\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"Size of train dataset (X, y): {} - {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Size of test dataset  (X, y): {} - {}\".format(X_test.shape, y_test.shape))\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "log_reg = LogisticRegression(class_weight='balanced')\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ad2de0d5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ad2de0d5",
    "outputId": "84b1d117-38f0-4d61-ebd5-253d7eaa9df8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset (X, y): (189, 76) - (189,)\n",
      "Size of test dataset  (X, y): (81, 76) - (81,)\n",
      "Accuracy: 0.8518518518518519\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.86        41\n",
      "           1       0.87      0.82      0.85        40\n",
      "\n",
      "    accuracy                           0.85        81\n",
      "   macro avg       0.85      0.85      0.85        81\n",
      "weighted avg       0.85      0.85      0.85        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = closeness_rs\n",
    "y = demographics_N['mstype'].values\n",
    "\n",
    "# split train test\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"Size of train dataset (X, y): {} - {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Size of test dataset  (X, y): {} - {}\".format(X_test.shape, y_test.shape))\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=500,class_weight='balanced')\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "68105957",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "68105957",
    "outputId": "cd41da7f-e845-4477-a6dc-233f77e2529c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset (X, y): (189, 76) - (189,)\n",
      "Size of test dataset  (X, y): (81, 76) - (81,)\n",
      "Accuracy: 0.7530864197530864\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.76      0.76        41\n",
      "           1       0.75      0.75      0.75        40\n",
      "\n",
      "    accuracy                           0.75        81\n",
      "   macro avg       0.75      0.75      0.75        81\n",
      "weighted avg       0.75      0.75      0.75        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = betweenness_rs\n",
    "y = demographics_N['mstype'].values\n",
    "\n",
    "# split train test\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"Size of train dataset (X, y): {} - {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Size of test dataset  (X, y): {} - {}\".format(X_test.shape, y_test.shape))\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "log_reg = LogisticRegression(class_weight='balanced')\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e9bbdd7d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e9bbdd7d",
    "outputId": "cdad0aaa-e8a5-4836-d344-39e4d1916c5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset (X, y): (189, 76) - (189,)\n",
      "Size of test dataset  (X, y): (81, 76) - (81,)\n",
      "Accuracy: 0.7407407407407407\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.80      0.76        41\n",
      "           1       0.77      0.68      0.72        40\n",
      "\n",
      "    accuracy                           0.74        81\n",
      "   macro avg       0.74      0.74      0.74        81\n",
      "weighted avg       0.74      0.74      0.74        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = eigenvector_rs\n",
    "y = demographics_N['mstype'].values\n",
    "\n",
    "# split train test\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"Size of train dataset (X, y): {} - {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Size of test dataset  (X, y): {} - {}\".format(X_test.shape, y_test.shape))\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=500, class_weight='balanced')\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6525a50",
   "metadata": {},
   "source": [
    "### GRAFS\n",
    "- average degree\n",
    "- average clustering\n",
    "- density"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a7056f",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "08a8dc3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset (X, y): (189, 1) - (189,)\n",
      "Size of test dataset  (X, y): (81, 1) - (81,)\n",
      "Accuracy: 0.8888888888888888\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.83      0.88        41\n",
      "           1       0.84      0.95      0.89        40\n",
      "\n",
      "    accuracy                           0.89        81\n",
      "   macro avg       0.89      0.89      0.89        81\n",
      "weighted avg       0.90      0.89      0.89        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = average_clustering_fa\n",
    "y = demographics_N['mstype'].values\n",
    "\n",
    "# split train test\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "print(\"Size of train dataset (X, y): {} - {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Size of test dataset  (X, y): {} - {}\".format(X_test.shape, y_test.shape))\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "svm = SVC(kernel='linear', C=1, class_weight='balanced')\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b631c02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset (X, y): (189, 1) - (189,)\n",
      "Size of test dataset  (X, y): (81, 1) - (81,)\n",
      "Accuracy: 0.9259259259259259\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.85      0.92        41\n",
      "           1       0.87      1.00      0.93        40\n",
      "\n",
      "    accuracy                           0.93        81\n",
      "   macro avg       0.93      0.93      0.93        81\n",
      "weighted avg       0.94      0.93      0.93        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = average_degree_fa\n",
    "y = demographics_N['mstype'].values\n",
    "\n",
    "# split train test\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "print(\"Size of train dataset (X, y): {} - {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Size of test dataset  (X, y): {} - {}\".format(X_test.shape, y_test.shape))\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "svm = SVC(kernel='linear', C=1, class_weight='balanced')\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1a95e8e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset (X, y): (189, 1) - (189,)\n",
      "Size of test dataset  (X, y): (81, 1) - (81,)\n",
      "Accuracy: 0.9259259259259259\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.85      0.92        41\n",
      "           1       0.87      1.00      0.93        40\n",
      "\n",
      "    accuracy                           0.93        81\n",
      "   macro avg       0.93      0.93      0.93        81\n",
      "weighted avg       0.94      0.93      0.93        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = density_fa\n",
    "y = demographics_N['mstype'].values\n",
    "\n",
    "# split train test\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "print(\"Size of train dataset (X, y): {} - {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Size of test dataset  (X, y): {} - {}\".format(X_test.shape, y_test.shape))\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "svm = SVC(kernel='linear', C=1, class_weight='balanced')\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "24d68f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset (X, y): (189, 1) - (189,)\n",
      "Size of test dataset  (X, y): (81, 1) - (81,)\n",
      "Accuracy: 0.9012345679012346\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.80      0.89        41\n",
      "           1       0.83      1.00      0.91        40\n",
      "\n",
      "    accuracy                           0.90        81\n",
      "   macro avg       0.92      0.90      0.90        81\n",
      "weighted avg       0.92      0.90      0.90        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = average_degree_gm\n",
    "y = demographics_N['mstype'].values\n",
    "\n",
    "# split train test\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "print(\"Size of train dataset (X, y): {} - {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Size of test dataset  (X, y): {} - {}\".format(X_test.shape, y_test.shape))\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "svm = SVC(kernel='linear', C=1, class_weight='balanced')\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "abf2490c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset (X, y): (189, 1) - (189,)\n",
      "Size of test dataset  (X, y): (81, 1) - (81,)\n",
      "Accuracy: 0.8765432098765432\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.76      0.86        41\n",
      "           1       0.80      1.00      0.89        40\n",
      "\n",
      "    accuracy                           0.88        81\n",
      "   macro avg       0.90      0.88      0.88        81\n",
      "weighted avg       0.90      0.88      0.87        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = average_clustering_gm\n",
    "y = demographics_N['mstype'].values\n",
    "\n",
    "# split train test\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "print(\"Size of train dataset (X, y): {} - {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Size of test dataset  (X, y): {} - {}\".format(X_test.shape, y_test.shape))\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "svm = SVC(kernel='linear', C=1, class_weight='balanced')\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0e76836d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset (X, y): (189, 1) - (189,)\n",
      "Size of test dataset  (X, y): (81, 1) - (81,)\n",
      "Accuracy: 0.9012345679012346\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.80      0.89        41\n",
      "           1       0.83      1.00      0.91        40\n",
      "\n",
      "    accuracy                           0.90        81\n",
      "   macro avg       0.92      0.90      0.90        81\n",
      "weighted avg       0.92      0.90      0.90        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = density_gm\n",
    "y = demographics_N['mstype'].values\n",
    "\n",
    "# split train test\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "print(\"Size of train dataset (X, y): {} - {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Size of test dataset  (X, y): {} - {}\".format(X_test.shape, y_test.shape))\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "svm = SVC(kernel='linear', C=1, class_weight='balanced')\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "677f3764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset (X, y): (189, 1) - (189,)\n",
      "Size of test dataset  (X, y): (81, 1) - (81,)\n",
      "Accuracy: 0.8765432098765432\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88        41\n",
      "           1       0.88      0.88      0.88        40\n",
      "\n",
      "    accuracy                           0.88        81\n",
      "   macro avg       0.88      0.88      0.88        81\n",
      "weighted avg       0.88      0.88      0.88        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = average_degree_rs\n",
    "y = demographics_N['mstype'].values\n",
    "\n",
    "# split train test\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "print(\"Size of train dataset (X, y): {} - {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Size of test dataset  (X, y): {} - {}\".format(X_test.shape, y_test.shape))\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "svm = SVC(kernel='linear', C=1, class_weight='balanced')\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "572dc04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset (X, y): (189, 1) - (189,)\n",
      "Size of test dataset  (X, y): (81, 1) - (81,)\n",
      "Accuracy: 0.7530864197530864\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.66      0.73        41\n",
      "           1       0.71      0.85      0.77        40\n",
      "\n",
      "    accuracy                           0.75        81\n",
      "   macro avg       0.76      0.75      0.75        81\n",
      "weighted avg       0.76      0.75      0.75        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = average_clustering_rs\n",
    "y = demographics_N['mstype'].values\n",
    "\n",
    "# split train test\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "print(\"Size of train dataset (X, y): {} - {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Size of test dataset  (X, y): {} - {}\".format(X_test.shape, y_test.shape))\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "svm = SVC(kernel='linear', C=1, class_weight='balanced')\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ccfab167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset (X, y): (189, 1) - (189,)\n",
      "Size of test dataset  (X, y): (81, 1) - (81,)\n",
      "Accuracy: 0.8765432098765432\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88        41\n",
      "           1       0.88      0.88      0.88        40\n",
      "\n",
      "    accuracy                           0.88        81\n",
      "   macro avg       0.88      0.88      0.88        81\n",
      "weighted avg       0.88      0.88      0.88        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = density_rs\n",
    "y = demographics_N['mstype'].values\n",
    "\n",
    "# split train test\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "print(\"Size of train dataset (X, y): {} - {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Size of test dataset  (X, y): {} - {}\".format(X_test.shape, y_test.shape))\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "svm = SVC(kernel='linear', C=1, class_weight='balanced')\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896aff78",
   "metadata": {},
   "source": [
    "#### LOGISTIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0c1d47c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset (X, y): (189, 1) - (189,)\n",
      "Size of test dataset  (X, y): (81, 1) - (81,)\n",
      "Accuracy: 0.9135802469135802\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.91        41\n",
      "           1       0.87      0.97      0.92        40\n",
      "\n",
      "    accuracy                           0.91        81\n",
      "   macro avg       0.92      0.91      0.91        81\n",
      "weighted avg       0.92      0.91      0.91        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = average_degree_fa\n",
    "y = demographics_N['mstype'].values\n",
    "\n",
    "# split train test\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"Size of train dataset (X, y): {} - {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Size of test dataset  (X, y): {} - {}\".format(X_test.shape, y_test.shape))\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "log_reg = LogisticRegression(class_weight='balanced')\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bafc5410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset (X, y): (189, 1) - (189,)\n",
      "Size of test dataset  (X, y): (81, 1) - (81,)\n",
      "Accuracy: 0.8518518518518519\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.83      0.85        41\n",
      "           1       0.83      0.88      0.85        40\n",
      "\n",
      "    accuracy                           0.85        81\n",
      "   macro avg       0.85      0.85      0.85        81\n",
      "weighted avg       0.85      0.85      0.85        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = average_clustering_fa\n",
    "y = demographics_N['mstype'].values\n",
    "\n",
    "# split train test\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"Size of train dataset (X, y): {} - {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Size of test dataset  (X, y): {} - {}\".format(X_test.shape, y_test.shape))\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "log_reg = LogisticRegression(class_weight='balanced')\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "30c014dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset (X, y): (189, 1) - (189,)\n",
      "Size of test dataset  (X, y): (81, 1) - (81,)\n",
      "Accuracy: 0.9135802469135802\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.91        41\n",
      "           1       0.87      0.97      0.92        40\n",
      "\n",
      "    accuracy                           0.91        81\n",
      "   macro avg       0.92      0.91      0.91        81\n",
      "weighted avg       0.92      0.91      0.91        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = density_fa\n",
    "y = demographics_N['mstype'].values\n",
    "\n",
    "# split train test\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"Size of train dataset (X, y): {} - {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Size of test dataset  (X, y): {} - {}\".format(X_test.shape, y_test.shape))\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "log_reg = LogisticRegression(class_weight='balanced')\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f4a4537d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset (X, y): (189, 1) - (189,)\n",
      "Size of test dataset  (X, y): (81, 1) - (81,)\n",
      "Accuracy: 0.9012345679012346\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.80      0.89        41\n",
      "           1       0.83      1.00      0.91        40\n",
      "\n",
      "    accuracy                           0.90        81\n",
      "   macro avg       0.92      0.90      0.90        81\n",
      "weighted avg       0.92      0.90      0.90        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = average_degree_gm\n",
    "y = demographics_N['mstype'].values\n",
    "\n",
    "# split train test\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"Size of train dataset (X, y): {} - {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Size of test dataset  (X, y): {} - {}\".format(X_test.shape, y_test.shape))\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "log_reg = LogisticRegression(class_weight='balanced')\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "15150007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset (X, y): (189, 1) - (189,)\n",
      "Size of test dataset  (X, y): (81, 1) - (81,)\n",
      "Accuracy: 0.9012345679012346\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.80      0.89        41\n",
      "           1       0.83      1.00      0.91        40\n",
      "\n",
      "    accuracy                           0.90        81\n",
      "   macro avg       0.92      0.90      0.90        81\n",
      "weighted avg       0.92      0.90      0.90        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = average_clustering_gm\n",
    "y = demographics_N['mstype'].values\n",
    "\n",
    "# split train test\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"Size of train dataset (X, y): {} - {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Size of test dataset  (X, y): {} - {}\".format(X_test.shape, y_test.shape))\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "log_reg = LogisticRegression(class_weight='balanced')\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5e8c0fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset (X, y): (189, 1) - (189,)\n",
      "Size of test dataset  (X, y): (81, 1) - (81,)\n",
      "Accuracy: 0.9012345679012346\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.80      0.89        41\n",
      "           1       0.83      1.00      0.91        40\n",
      "\n",
      "    accuracy                           0.90        81\n",
      "   macro avg       0.92      0.90      0.90        81\n",
      "weighted avg       0.92      0.90      0.90        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = density_gm\n",
    "y = demographics_N['mstype'].values\n",
    "\n",
    "# split train test\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"Size of train dataset (X, y): {} - {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Size of test dataset  (X, y): {} - {}\".format(X_test.shape, y_test.shape))\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "log_reg = LogisticRegression(class_weight='balanced')\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e79a4c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset (X, y): (189, 1) - (189,)\n",
      "Size of test dataset  (X, y): (81, 1) - (81,)\n",
      "Accuracy: 0.8641975308641975\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87        41\n",
      "           1       0.87      0.85      0.86        40\n",
      "\n",
      "    accuracy                           0.86        81\n",
      "   macro avg       0.86      0.86      0.86        81\n",
      "weighted avg       0.86      0.86      0.86        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = average_degree_rs\n",
    "y = demographics_N['mstype'].values\n",
    "\n",
    "# split train test\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"Size of train dataset (X, y): {} - {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Size of test dataset  (X, y): {} - {}\".format(X_test.shape, y_test.shape))\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "log_reg = LogisticRegression(class_weight='balanced')\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "96b7d758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset (X, y): (189, 1) - (189,)\n",
      "Size of test dataset  (X, y): (81, 1) - (81,)\n",
      "Accuracy: 0.7654320987654321\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.73      0.76        41\n",
      "           1       0.74      0.80      0.77        40\n",
      "\n",
      "    accuracy                           0.77        81\n",
      "   macro avg       0.77      0.77      0.77        81\n",
      "weighted avg       0.77      0.77      0.77        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = average_clustering_rs\n",
    "y = demographics_N['mstype'].values\n",
    "\n",
    "# split train test\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"Size of train dataset (X, y): {} - {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Size of test dataset  (X, y): {} - {}\".format(X_test.shape, y_test.shape))\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "log_reg = LogisticRegression(class_weight='balanced')\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "23f16bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset (X, y): (189, 1) - (189,)\n",
      "Size of test dataset  (X, y): (81, 1) - (81,)\n",
      "Accuracy: 0.8641975308641975\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87        41\n",
      "           1       0.87      0.85      0.86        40\n",
      "\n",
      "    accuracy                           0.86        81\n",
      "   macro avg       0.86      0.86      0.86        81\n",
      "weighted avg       0.86      0.86      0.86        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = density_rs\n",
    "y = demographics_N['mstype'].values\n",
    "\n",
    "# split train test\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"Size of train dataset (X, y): {} - {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Size of test dataset  (X, y): {} - {}\".format(X_test.shape, y_test.shape))\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "log_reg = LogisticRegression(class_weight='balanced')\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
